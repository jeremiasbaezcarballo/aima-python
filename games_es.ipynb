{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# JUEGOS O B\u00daSQUEDA ADVERSARIAL\n", "\n", "Este cuaderno sirve como material de apoyo para los temas tratados en el **Cap\u00edtulo 5: B\u00fasqueda adversaria** del libro *Inteligencia artificial: un enfoque moderno.* Este cuaderno utiliza implementaciones del m\u00f3dulo [games.py](https://github.com/aimacode/aima-python/blob/master/games.py). Importemos las clases, m\u00e9todos, variables globales, etc. requeridos, desde el m\u00f3dulo de juegos."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# CONTENIDO\n", "\n", "* Representaci\u00f3n del juego\n", "* Ejemplos de juegos\n", "* Tres en raya\n", "* Figura 5.2 Juego\n", "* M\u00ednimo m\u00e1ximo\n", "* Alfa Beta\n", "* Jugadores\n", "* \u00a1Juguemos algunos juegos!"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"collapsed": true}, "outputs": [], "source": ["from games import *\n", "from notebook import psource, pseudocode"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# REPRESENTACI\u00d3N DEL JUEGO\n", "\n", "Para representar juegos utilizamos la clase `Game`, que podemos subclasificar y anular sus funciones para representar nuestros propios juegos. Una herramienta de ayuda es la tupla nombrada `GameState`, que en algunos casos puede resultar \u00fatil, especialmente cuando nuestro juego necesita que recordemos un tablero (como el ajedrez)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## `GameState` llamado tupla\n", "\n", "`GameState` es un [namedtuple](https://docs.python.org/3.5/library/collections.html#collections.namedtuple) que representa el estado actual de un juego. Se utiliza para ayudar a representar juegos cuyos estados no se pueden representar f\u00e1cilmente normalmente, o para juegos que requieren memoria de un tablero, como Tic-Tac-Toe.\n", "\n", "`Gamestate` se define de la siguiente manera:\n", "\n", "`GameState = nametuple('GameState', 'to_move, utilidad, tablero, movimientos')`\n", "\n", "* `to_move`: Representa a qui\u00e9n le toca moverse a continuaci\u00f3n.\n", "\n", "* `utilidad`: Almacena la utilidad del estado del juego. Almacenar esta utilidad es una buena idea porque, cuando realiza una b\u00fasqueda Minimax o una b\u00fasqueda Alphabeta, genera muchas llamadas recursivas, que viajan hasta los estados terminales. Cuando estas llamadas recursivas regresan al destinatario original, hemos calculado utilidades para muchos estados del juego. Almacenamos estas utilidades en sus respectivos `GameState` para evitar calcularlas nuevamente.\n", "\n", "* `tablero`: Un dictado que almacena el tablero del juego.\n", "\n", "* `moves`: Almacena la lista de movimientos legales posibles desde la posici\u00f3n actual."]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Clase `Juego`\n", "\n", "Echemos un vistazo a la clase \"Juego\" en nuestro m\u00f3dulo. Vemos que tiene funciones, a saber, `acciones`, `resultado`, `utilidad`, `terminal_test`, `to_move` y `display`.\n", "\n", "Vemos que estas funciones en realidad no se han implementado. Esta clase es s\u00f3lo una clase de plantilla; Se supone que debemos crear la clase para nuestro juego, heredando esta clase \"Juego\" e implementando todos los m\u00e9todos mencionados en \"Juego\"."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["%psource Game"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora entremos en detalles de todos los m\u00e9todos de nuestra clase \"Juego\". Tienes que implementar estos m\u00e9todos cuando creas nuevas clases que representen tu juego.\n", "\n", "* `acciones(self, state)`: Dado un estado del juego, este m\u00e9todo genera todas las acciones legales posibles a partir de este estado, como una lista o un generador. Devolver un generador en lugar de una lista tiene la ventaja de que ahorra espacio y a\u00fan puede operar con \u00e9l como una lista.\n", "\n", "\n", "* `resultado(self, state, move)`: dado un estado de juego y un movimiento, este m\u00e9todo devuelve el estado de juego que se obtiene al realizar ese movimiento en este estado de juego.\n", "\n", "\n", "* `utilidad(self, state, player)`: dado un estado de juego terminal y un jugador, este m\u00e9todo devuelve la utilidad para ese jugador en el estado de juego terminal dado. Al implementar este m\u00e9todo, suponga que el estado del juego es un estado de juego terminal. La l\u00f3gica de este m\u00f3dulo es tal que este m\u00e9todo s\u00f3lo se llamar\u00e1 en estados de juego de terminal.\n", "\n", "\n", "* `terminal_test(self, state)`: Dado un estado del juego, este m\u00e9todo deber\u00eda devolver `True` si este estado del juego es un estado terminal, y `False` en caso contrario.\n", "\n", "\n", "* `to_move(self, state)`: dado el estado del juego, este m\u00e9todo devuelve el jugador que jugar\u00e1 a continuaci\u00f3n. Esta informaci\u00f3n normalmente se almacena en el estado del juego, por lo que todo lo que hace este m\u00e9todo es extraer esta informaci\u00f3n y devolverla.\n", "\n", "\n", "* `display(self, state)`: Este m\u00e9todo imprime/muestra el estado actual del juego."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# EJEMPLOS DE JUEGOS\n", "\n", "A continuaci\u00f3n te damos algunos ejemplos de juegos que puedes crear y experimentar."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Tres en raya\n", "\n", "Eche un vistazo a la clase \"TicTacToe\". Todos los m\u00e9todos mencionados en la clase \"Juego\" se han implementado aqu\u00ed."]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": true}, "outputs": [{"output_type": "stream", "text": "\u001b[1;32mclass\u001b[0m \u001b[0mTicTacToe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;34m\"\"\"Play TicTacToe on an h x v board, with Max (first player) playing 'X'.\n    A state has the player to move, a cached utility, a list of moves in\n    the form of a list of (x, y) positions, and a board, in the form of\n    a dict of {(x, y): Player} entries, where Player is 'X' or 'O'.\"\"\"\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mmoves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGameState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoves\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;34m\"\"\"Legal moves are any square not yet taken.\"\"\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m  \u001b[1;31m# Illegal move has no effect\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mboard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mmoves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mmoves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mGameState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'O'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_move\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'X'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                         \u001b[0mutility\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_utility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_move\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n\u001b[0m                         \u001b[0mboard\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoves\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;34m\"\"\"Return the value to player; 1 for win, -1 for loss, 0 otherwise.\"\"\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'X'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mterminal_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;34m\"\"\"A state is terminal if it is won or there are no empty squares.\"\"\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutility\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mcompute_utility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;34m\"\"\"If 'X' wins with this move, return 1; if 'O' wins return -1; else return 0.\"\"\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_in_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_in_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_in_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\n\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_in_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mplayer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'X'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n\u001b[0m\u001b[1;33m\n\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mk_in_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_x_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;34m\"\"\"Return true if there is a line through move on board for player.\"\"\"\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;33m(\u001b[0m\u001b[0mdelta_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta_x_y\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m  \u001b[1;31m# n is number of moves in row\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mwhile\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdelta_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdelta_y\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mwhile\u001b[0m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n\u001b[0m            \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdelta_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdelta_y\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[0mn\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# Because we counted move itself twice\u001b[0m\u001b[1;33m\n\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "metadata": {}, "execution_count": 4}], "source": ["%psource TicTacToe"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La clase `TicTacToe` ha sido heredada de la clase `Game`. Como se mencion\u00f3 anteriormente, realmente quieres hacer esto. Detectar errores y errores se vuelve mucho m\u00e1s f\u00e1cil.\n", "\n", "M\u00e9todos adicionales en TicTacToe:\n", "\n", "* `__init__(self, h=3, v=3, k=3)` : Cuando creas una clase heredada de la clase `Game` (clase `TicTacToe` en nuestro caso), tendr\u00e1s que crear un objeto de esta clase heredada para inicializar el juego. Esta inicializaci\u00f3n podr\u00eda requerir informaci\u00f3n adicional que se pasar\u00eda a `__init__` como variables. Para el caso de nuestro juego `TicTacToe`, esta informaci\u00f3n adicional ser\u00eda el n\u00famero de filas `h`, el n\u00famero de columnas `v` y cu\u00e1ntas X u O consecutivas se necesitan en una fila, columna o diagonal para ganar `k `. Adem\u00e1s, el estado inicial del juego debe definirse aqu\u00ed en `__init__`.\n", "\n", "\n", "* `compute_utility(self, board, move, player)`: un m\u00e9todo para calcular la utilidad del juego TicTacToe. Si 'X' gana con este movimiento, este m\u00e9todo devuelve 1; si 'O' gana, devuelve -1; de lo contrario devuelve 0.\n", "\n", "\n", "* `k_in_row(self, board, move, player, delta_x_y)`: este m\u00e9todo devuelve `True` si hay una l\u00ednea formada en el tablero de TicTacToe con el \u00faltimo movimiento; de lo contrario, `False.`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Estado del juego TicTacToe\n", "\n", "Ahora, antes de comenzar a implementar nuestro juego \"TicTacToe\", debemos decidir c\u00f3mo representaremos el estado de nuestro juego. Normalmente, el estado de un juego te brindar\u00e1 toda la informaci\u00f3n actual sobre el juego en cualquier momento. Cuando se te da un estado de juego, deber\u00edas poder saber qui\u00e9n es el siguiente turno, c\u00f3mo se ver\u00e1 el juego en un tablero de la vida real (si lo tiene), etc. No es necesario que un estado de juego incluya la historia del juego. Si puedes seguir jugando el juego dado un estado del juego, la representaci\u00f3n del estado del juego es aceptable. Si bien es posible que nos guste incluir todo tipo de informaci\u00f3n en el estado de nuestro juego, no queremos incluir demasiada informaci\u00f3n en \u00e9l. Modificar este estado del juego para generar uno nuevo ser\u00eda una verdadera molestia entonces.\n", "\n", "Ahora, en cuanto al estado de nuestro juego \"TicTacToe\", \u00bfser\u00eda suficiente almacenar solo las posiciones de todas las X y O para representar toda la informaci\u00f3n del juego en ese momento? Bueno, \u00bfnos dice a qui\u00e9n le toca el siguiente? Mirar las \"X\" y las \"O\" en el tablero y contarlas deber\u00eda decirnos eso. Pero eso significar\u00eda computaci\u00f3n adicional. Para evitar esto, tambi\u00e9n almacenaremos cu\u00e1l es el siguiente movimiento en el estado del juego.\n", "\n", "Piensa en lo que hemos hecho aqu\u00ed. Hemos reducido el c\u00e1lculo adicional al almacenar informaci\u00f3n adicional en un estado de juego. Ahora bien, es posible que esta informaci\u00f3n no sea absolutamente esencial para informarnos sobre el estado del juego, pero nos ahorra tiempo de c\u00e1lculo adicional. Haremos m\u00e1s de esto m\u00e1s adelante."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Para almacenar los estados del juego se utilizar\u00e1 la tupla nombrada `GameState`.\n", "\n", "* `to_move`: Una cadena de un solo car\u00e1cter, ya sea 'X' u 'O'.\n", "\n", "* `utilidad`: 1 por victoria, -1 por p\u00e9rdida, 0 en caso contrario.\n", "\n", "* `tablero`: Todas las posiciones de las X y las O en el tablero.\n", "\n", "* `moves`: Todos los movimientos posibles desde el estado actual. Tenga en cuenta aqu\u00ed que almacenar los movimientos como una lista, como se hace aqu\u00ed, aumenta la complejidad espacial de la b\u00fasqueda Minimax de `O(m)` a `O(bm)`. Consulte la secci\u00f3n 5.2.1 del libro."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Representando un movimiento en el juego TicTacToe\n", "\n", "Ahora que hemos decidido c\u00f3mo se representar\u00e1 el estado de nuestro juego, es hora de decidir c\u00f3mo se representar\u00e1 nuestro movimiento. Resulta f\u00e1cil usar este movimiento para modificar el estado actual del juego y generar uno nuevo.\n", "\n", "Para nuestro juego \"TicTacToe\", simplemente representaremos un movimiento mediante una tupla, donde el primer y segundo elemento de la tupla representar\u00e1n la fila y la columna, respectivamente, donde se realizar\u00e1 el siguiente movimiento. Si hacer una 'X' o una 'O' lo decidir\u00e1 `to_move` en la tupla nombrada `GameState`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Juego Fig52\n", "\n", "Para un ejemplo m\u00e1s trivial representaremos el juego en la **Figura 5.2** del libro.\n", "\n", "<img src=\"images/fig_5_2.png\" width=\"75%\">\n", "\n", "Los estados se representan con letras may\u00fasculas dentro de los tri\u00e1ngulos (por ejemplo, \"A\") mientras que los movimientos son las etiquetas en los bordes entre estados (por ejemplo, \"a1\"). Los nodos terminales llevan valores de utilidad. Tenga en cuenta que los nodos terminales se denominan en este ejemplo 'B1', 'B2' y 'B2' para los nodos debajo de 'B', y as\u00ed sucesivamente.\n", "\n", "Modelaremos los movimientos, utilidades y estado inicial as\u00ed:"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"collapsed": true}, "outputs": [], "source": ["moves = dict(A=dict(a1='B', a2='C', a3='D'),\n", "                 B=dict(b1='B1', b2='B2', b3='B3'),\n", "                 C=dict(c1='C1', c2='C2', c3='C3'),\n", "                 D=dict(d1='D1', d2='D2', d3='D3'))\n", "utils = dict(B1=3, B2=12, B3=8, C1=2, C2=4, C3=6, D1=14, D2=5, D3=2)\n", "initial = 'A'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En \"movimientos\", tenemos un sistema de diccionario anidado. El diccionario externo tiene claves como estados y valores de los posibles movimientos desde ese estado (como diccionario). El diccionario interno de movimientos tiene claves que nombran los movimientos y valoran el siguiente estado despu\u00e9s de que se completa el movimiento.\n", "\n", "A continuaci\u00f3n se muestra un ejemplo que muestra \"movimientos\". Queremos el siguiente estado despu\u00e9s del movimiento 'a1' de 'A', que es 'B'. Un vistazo r\u00e1pido a la imagen de arriba confirma que este es efectivamente el caso."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["B\n"]}], "source": ["print(moves['A']['a1'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora veremos las funciones que necesitamos implementar. Primero necesitamos crear un objeto de la clase `Fig52Game`."]}, {"cell_type": "code", "execution_count": 6, "metadata": {"collapsed": true}, "outputs": [], "source": ["fig52 = Fig52Game()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`acciones`: Devuelve la lista de movimientos que uno puede realizar desde un estado determinado."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(Fig52Game.actions)"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['b1', 'b2', 'b3']\n"]}], "source": ["print(fig52.actions('B'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`resultado`: Devuelve el siguiente estado despu\u00e9s de realizar un movimiento espec\u00edfico."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(Fig52Game.result)"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["B\n"]}], "source": ["print(fig52.result('A', 'a1'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`utilidad`: Devuelve el valor del estado terminal de un jugador ('MAX' y 'MIN'). Tenga en cuenta que para 'MIN' el valor devuelto es el negativo de la utilidad."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(Fig52Game.utility)"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["3\n", "-3\n"]}], "source": ["print(fig52.utility('B1', 'MAX'))\n", "print(fig52.utility('B1', 'MIN'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`terminal_test`: Devuelve `Verdadero` si el estado dado es un estado terminal, `Falso` en caso contrario."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(Fig52Game.terminal_test)"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["True\n"]}], "source": ["print(fig52.terminal_test('C3'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`to_move`: Devuelve el jugador que se mover\u00e1 en este estado."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(Fig52Game.to_move)"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["MAX\n"]}], "source": ["print(fig52.to_move('A'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["En su conjunto la clase `Fig52` que hereda de la clase `Game` y anula sus funciones:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(Fig52Game)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# M\u00cdNIMO M\u00c1XIMO\n", "\n", "## Descripci\u00f3n general\n", "\n", "Este algoritmo (a menudo llamado *Minimax*) calcula el siguiente movimiento de un jugador (MIN o MAX) en su estado actual. Calcula recursivamente el valor minimax de los estados sucesores, hasta que llega a las terminales (las hojas del \u00e1rbol). Utilizando el valor de \"utilidad\" de los estados terminales, calcula los valores de los estados principales hasta que llega al nodo inicial (la ra\u00edz del \u00e1rbol).\n", "\n", "Vale la pena se\u00f1alar que el algoritmo funciona primero en profundidad. El pseudoc\u00f3digo se puede encontrar a continuaci\u00f3n:"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/markdown": ["### AIMA3e\n", "__function__ MINIMAX-DECISION(_state_) __returns__ _an action_  \n", "&emsp;__return__ arg max<sub> _a_ &Element; ACTIONS(_s_)</sub> MIN\\-VALUE(RESULT(_state_, _a_))  \n", "\n", "---\n", "__function__ MAX\\-VALUE(_state_) __returns__ _a utility value_  \n", "&emsp;__if__ TERMINAL\\-TEST(_state_) __then return__ UTILITY(_state_)  \n", "&emsp;_v_ &larr; &minus;&infin;  \n", "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n", "&emsp;&emsp;&emsp;_v_ &larr; MAX(_v_, MIN\\-VALUE(RESULT(_state_, _a_)))  \n", "&emsp;__return__ _v_  \n", "\n", "---\n", "__function__ MIN\\-VALUE(_state_) __returns__ _a utility value_  \n", "&emsp;__if__ TERMINAL\\-TEST(_state_) __then return__ UTILITY(_state_)  \n", "&emsp;_v_ &larr; &infin;  \n", "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n", "&emsp;&emsp;&emsp;_v_ &larr; MIN(_v_, MAX\\-VALUE(RESULT(_state_, _a_)))  \n", "&emsp;__return__ _v_  \n", "\n", "---\n", "__Figure__ ?? An algorithm for calculating minimax decisions. It returns the action corresponding to the best possible move, that is, the move that leads to the outcome with the best utility, under the assumption that the opponent plays to minimize utility. The functions MAX\\-VALUE and MIN\\-VALUE go through the whole game tree, all the way to the leaves, to determine the backed\\-up value of a state. The notation argmax <sub>_a_ &Element; _S_</sub> _f_(_a_) computes the element _a_ of set _S_ that has maximum value of _f_(_a_)."], "text/plain": ["<IPython.core.display.Markdown object>"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["pseudocode(\"Minimax-Decision\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Implementaci\u00f3n\n", "\n", "En la implementaci\u00f3n estamos usando dos funciones, `max_value` y `min_value` para calcular el mejor movimiento para MAX y MIN respectivamente. Estas funciones interact\u00faan en una recursi\u00f3n alterna; uno llama al otro hasta que se alcanza un estado terminal. Cuando la recursividad se detiene, nos quedan puntuaciones para cada movimiento. Devolvemos el m\u00e1ximo. A pesar de devolver el m\u00e1ximo, tambi\u00e9n funcionar\u00e1 para MIN, ya que para MIN los valores son negativos (por lo tanto, el orden de los valores se invierte, por lo que cuanto m\u00e1s alto, mejor tambi\u00e9n para MIN)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "outputs": [], "source": ["psource(minimax_decision)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ejemplo\n", "\n", "Ahora jugaremos al juego Fig52 usando este algoritmo. Eche un vistazo al Fig52Game desde arriba para seguirlo.\n", "\n", "Es el turno de MAX de moverse, y est\u00e1 en el estado A. Puede moverse a B, C o D, usando los movimientos a1, a2 y a3 respectivamente. El objetivo de MAX es maximizar el valor final. Entonces, para tomar una decisi\u00f3n, MAX necesita conocer los valores en los nodos antes mencionados y elegir el mayor. Despu\u00e9s de MAX, le toca jugar a MIN. Entonces MAX quiere saber cu\u00e1les ser\u00e1n los valores de B, C y D despu\u00e9s de que MIN juegue.\n", "\n", "El problema entonces es qu\u00e9 movimiento har\u00e1 MIN en B, C y D. Los estados sucesores de todos estos nodos son estados terminales, por lo que MIN elegir\u00e1 el valor m\u00e1s peque\u00f1o para cada nodo. Entonces, para B elegir\u00e1 3 (del movimiento b1), para C elegir\u00e1 2 (del movimiento c1) y para D volver\u00e1 a elegir 2 (del movimiento d3).\n", "\n", "Veamos esto en c\u00f3digo:"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b1\n", "c1\n", "d3\n"]}], "source": ["print(minimax_decision('B', fig52))\n", "print(minimax_decision('C', fig52))\n", "print(minimax_decision('D', fig52))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora MAX sabe que los valores de B, C y D son 3, 2 y 2 (producidos por los movimientos anteriores de MIN). El mayor es 3, que obtendr\u00e1 con la jugada a1. Este es entonces el movimiento que realizar\u00e1 MAX. Veamos el algoritmo en plena acci\u00f3n:"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["a1\n"]}], "source": ["print(minimax_decision('A', fig52))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualizaci\u00f3n\n", "\n", "A continuaci\u00f3n tenemos una visualizaci\u00f3n de juego simple usando el algoritmo. Despu\u00e9s de ejecutar el comando, haz clic en la celda para avanzar en el juego. Puede ingresar sus propios valores a trav\u00e9s de una lista de 27 n\u00fameros enteros."]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["from notebook import Canvas_minimax\n", "from random import randint"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["minimax_viz = Canvas_minimax('minimax_viz', [randint(1, 50) for i in range(27)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# ALFA BETA\n", "\n", "## Descripci\u00f3n general\n", "\n", "Si bien *Minimax* es fant\u00e1stico para calcular un movimiento, puede resultar complicado cuando el n\u00famero de estados del juego aumenta. El algoritmo necesita buscar todas las hojas del \u00e1rbol, que aumentan exponencialmente a su profundidad.\n", "\n", "Para Tic-Tac-Toe, donde la profundidad del \u00e1rbol es 9 (despu\u00e9s del noveno movimiento, el juego termina), \u00a1podemos tener como m\u00e1ximo 9! estados terminales (como m\u00e1ximo porque no todos los nodos terminales est\u00e1n en el \u00faltimo nivel del \u00e1rbol; algunos est\u00e1n m\u00e1s arriba porque el juego termin\u00f3 antes del noveno movimiento). Esto no es tan malo, pero para problemas m\u00e1s complejos como el ajedrez, tenemos m\u00e1s de $10^{40}$ nodos terminales. Desafortunadamente no hemos encontrado una manera de eliminar el exponente, pero s\u00ed hemos encontrado formas de aliviar la carga de trabajo.\n", "\n", "Aqu\u00ed examinamos *podar* el \u00e1rbol del juego, lo que significa eliminar partes del mismo que no necesitamos examinar. El tipo particular de poda se llama *alfa-beta*, y la b\u00fasqueda en su totalidad se llama *b\u00fasqueda alfa-beta*.\n", "\n", "Para mostrar qu\u00e9 partes del \u00e1rbol no necesitamos buscar, veremos el ejemplo `Fig52Game`.\n", "\n", "En el juego de ejemplo, necesitamos encontrar el mejor movimiento para el jugador MAX en el estado A, que es el valor m\u00e1ximo de los movimientos posibles de MIN en los estados sucesores.\n", "\n", "`M\u00c1X(A) = M\u00c1X(M\u00cdN(B), M\u00cdN(C), M\u00cdN(D))`\n", "\n", "`MIN(B)` es el m\u00ednimo de 3, 12, 8, que es 3. Entonces la f\u00f3rmula anterior se convierte en:\n", "\n", "`M\u00c1X(A) = M\u00c1X(3, M\u00cdN(C), M\u00cdN(D))`\n", "\n", "El siguiente movimiento que comprobaremos es c1, lo que conduce a un estado terminal con utilidad de 2. Antes de continuar buscando en el estado C, volvamos a nuestra f\u00f3rmula con el nuevo valor:\n", "\n", "`MAX(A) = MAX(3, MIN(2, c2, .... cN), MIN(D) )`\n", "\n", "No sabemos cu\u00e1ntos movimientos permite el estado C, pero sabemos que el primero da como resultado un valor de 2. \u00bfNecesitamos seguir buscando en C? La respuesta es no. El valor que MIN seleccionar\u00e1 en C ser\u00e1 como m\u00e1ximo 2. Dado que MAX ya tiene la opci\u00f3n de elegir algo mayor que eso, 3 de B, no necesita seguir buscando en C.\n", "\n", "En *alfa-beta* utilizamos dos par\u00e1metros adicionales para cada estado/nodo, *a* y *b*, que describen los l\u00edmites de los posibles movimientos. El par\u00e1metro *a* denota la mejor opci\u00f3n (valor m\u00e1s alto) para MAX a lo largo de esa ruta, mientras que *b* denota la mejor opci\u00f3n (valor m\u00e1s bajo) para MIN. A medida que avanzamos actualizamos *a* y *b* y podamos una rama de nodo cuando el valor del nodo es peor que el valor de *a* y *b* para MAX y MIN respectivamente.\n", "\n", "En el ejemplo anterior, despu\u00e9s de la b\u00fasqueda en el estado B, MAX ten\u00eda un valor *a* de 3. Entonces, al buscar en el nodo C encontramos un valor menor que ese, 2, dejamos de buscar en C.\n", "\n", "Puedes leer el pseudoc\u00f3digo a continuaci\u00f3n:"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/markdown": ["### AIMA3e\n", "__function__ ALPHA-BETA-SEARCH(_state_) __returns__ an action  \n", "&emsp;_v_ &larr; MAX\\-VALUE(_state_, &minus;&infin;, &plus;&infin;)  \n", "&emsp;__return__ the _action_ in ACTIONS(_state_) with value _v_  \n", "\n", "---\n", "__function__ MAX\\-VALUE(_state_, _&alpha;_, _&beta;_) __returns__ _a utility value_  \n", "&emsp;__if__ TERMINAL\\-TEST(_state_) __then return__ UTILITY(_state_)  \n", "&emsp;_v_ &larr; &minus;&infin;  \n", "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n", "&emsp;&emsp;&emsp;_v_ &larr; MAX(_v_, MIN\\-VALUE(RESULT(_state_, _a_), _&alpha;_, _&beta;_))  \n", "&emsp;&emsp;&emsp;__if__ _v_ &ge; _&beta;_ __then return__ _v_  \n", "&emsp;&emsp;&emsp;_&alpha;_ &larr; MAX(_&alpha;_, _v_)  \n", "&emsp;__return__ _v_  \n", "\n", "---\n", "__function__ MIN\\-VALUE(_state_, _&alpha;_, _&beta;_) __returns__ _a utility value_  \n", "&emsp;__if__ TERMINAL\\-TEST(_state_) __then return__ UTILITY(_state_)  \n", "&emsp;_v_ &larr; &plus;&infin;  \n", "&emsp;__for each__ _a_ __in__ ACTIONS(_state_) __do__  \n", "&emsp;&emsp;&emsp;_v_ &larr; MIN(_v_, MAX\\-VALUE(RESULT(_state_, _a_), _&alpha;_, _&beta;_))  \n", "&emsp;&emsp;&emsp;__if__ _v_ &le; _&alpha;_ __then return__ _v_  \n", "&emsp;&emsp;&emsp;_&beta;_ &larr; MIN(_&beta;_, _v_)  \n", "&emsp;__return__ _v_  \n", "\n", "\n", "---\n", "__Figure__ ?? The alpha\\-beta search algorithm. Notice that these routines are the same as the MINIMAX functions in Figure ??, except for the two lines in each of MIN\\-VALUE and MAX\\-VALUE that maintain _&alpha;_ and _&beta;_ (and the bookkeeping to pass these parameters along)."], "text/plain": ["<IPython.core.display.Markdown object>"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["pseudocode(\"Alpha-Beta-Search\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Implementaci\u00f3n\n", "\n", "Al igual que *minimax*, volvemos a utilizar las funciones `max_value` y `min_value`, pero esta vez utilizamos los valores *a* y *b*, actualiz\u00e1ndolos y deteniendo la llamada recursiva si terminamos en nodos con valores peores. que *a* y *b* (para MAX y MIN). El algoritmo encuentra el valor m\u00e1ximo y devuelve el movimiento que lo genera.\n", "\n", "La implementaci\u00f3n:"]}, {"cell_type": "code", "execution_count": 21, "metadata": {"collapsed": true}, "outputs": [], "source": ["%psource alphabeta_search"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ejemplo\n", "\n", "Jugaremos al juego Fig52 con el algoritmo de b\u00fasqueda *alfa-beta*. Es el turno de MAX de jugar en el estado A."]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["a1\n"]}], "source": ["print(alphabeta_search('A', fig52))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["El movimiento \u00f3ptimo para MAX es a1, por las razones expuestas anteriormente. MIN elegir\u00e1 el movimiento b1 para B, lo que dar\u00e1 como resultado un valor de 3, actualizando el valor *a* de MAX a 3. Luego, cuando encontremos en C un nodo de valor 2, dejaremos de buscar en ese sub\u00e1rbol ya que es menor que *a*. De D tenemos un valor de 2. Entonces, el mejor movimiento para MAX es el que da como resultado un valor de 3, que es a1.\n", "\n", "A continuaci\u00f3n vemos los mejores movimientos para MIN comenzando desde B, C y D respectivamente. Tenga en cuenta que el algoritmo en estos casos funciona de la misma manera que *minimax*, ya que todos los nodos debajo de los estados antes mencionados son terminales."]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b1\n", "c1\n", "d3\n"]}], "source": ["print(alphabeta_search('B', fig52))\n", "print(alphabeta_search('C', fig52))\n", "print(alphabeta_search('D', fig52))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualizaci\u00f3n\n", "\n", "A continuaci\u00f3n encontrar\u00e1s la visualizaci\u00f3n del algoritmo alfa-beta para un juego sencillo. Haz clic en la celda despu\u00e9s de ejecutar el comando para avanzar en el juego. Puede ingresar sus propios valores a trav\u00e9s de una lista de 27 n\u00fameros enteros."]}, {"cell_type": "code", "execution_count": 2, "metadata": {"collapsed": true}, "outputs": [], "source": ["from notebook import Canvas_alphabeta\n", "from random import randint"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["alphabeta_viz = Canvas_alphabeta('alphabeta_viz', [randint(1, 50) for i in range(27)])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# JUGADORES\n", "\n", "Entonces, hemos terminado la implementaci\u00f3n de las clases `TicTacToe` y `Fig52Game`. Estas clases lo que hacen es definir las reglas de los juegos. Necesitamos m\u00e1s para crear una IA que realmente pueda jugar. Aqu\u00ed es donde entran `random_player` y `alphabeta_player`.\n", "\n", "## jugador_consulta\n", "La funci\u00f3n `query_player` te permite a ti, un oponente humano, jugar. Esta funci\u00f3n requiere que se implemente un m\u00e9todo \"display\" en su clase de juego, de modo que los estados sucesivos del juego puedan mostrarse en el terminal, lo que le facilitar\u00e1 visualizar el juego y jugar en consecuencia.\n", "\n", "## jugador_aleatorio\n", "El `random_player` es una funci\u00f3n que realiza movimientos aleatorios en el juego. Eso es todo. No hay mucho m\u00e1s para este chico.\n", "\n", "## alfabeto_player\n", "El `alphabeta_player`, por otro lado, llama a la funci\u00f3n `alphabeta_search`, que devuelve el mejor movimiento en el estado actual del juego. Por lo tanto, `alphabeta_player` siempre realiza el mejor movimiento dado el estado del juego, asumiendo que el \u00e1rbol del juego es lo suficientemente peque\u00f1o como para realizar una b\u00fasqueda completa.\n", "\n", "## minimax_player\n", "El `minimax_player`, por otro lado, llama a la funci\u00f3n `minimax_search` que devuelve el mejor movimiento en el estado actual del juego.\n", "\n", "## jugar un juego\n", "La funci\u00f3n `play_game` ser\u00e1 la que realmente se utilizar\u00e1 para jugar. Le pasas como argumentos una instancia del juego que quieres jugar y los jugadores que quieres en este juego. \u00a1\u00daselo para jugar partidas de IA contra IA, IA contra humanos o incluso partidos de humano contra humano!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u00a1JUEGUEMOS ALGUNOS JUEGOS!\n", "\n", "##\n", "\n", "Comencemos experimentando primero con `Fig52Game`. Para eso crearemos una instancia de la subclase Fig52Game heredada de la clase Game:"]}, {"cell_type": "code", "execution_count": 27, "metadata": {"collapsed": true}, "outputs": [], "source": ["game52 = Fig52Game()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Primero probamos nuestro `random_player(game, state)`. Dado un estado del juego, nos dar\u00e1 un movimiento aleatorio cada vez:"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["a1\n", "a3\n"]}], "source": ["print(random_player(game52, 'A'))\n", "print(random_player(game52, 'A'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["El `alphabeta_player(game, state)` siempre nos dar\u00e1 el mejor movimiento posible, para el jugador relevante (MAX o MIN):"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["a1\n", "b1\n", "c1\n"]}], "source": ["print( alphabeta_player(game52, 'A') )\n", "print( alphabeta_player(game52, 'B') )\n", "print( alphabeta_player(game52, 'C') )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lo que hace `alphabeta_player` es simplemente llamar al m\u00e9todo `alphabeta_full_search`. Ambos son esencialmente iguales. En el m\u00f3dulo se han implementado tanto `alphabeta_full_search` como `minimax_decision`. Ambos hacen el mismo trabajo y devuelven lo mismo, que es el mejor movimiento en el estado actual. Es solo que `alphabeta_full_search` es m\u00e1s eficiente con respecto al tiempo porque poda el \u00e1rbol de b\u00fasqueda y, por lo tanto, explora un menor n\u00famero de estados."]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [{"data": {"text/plain": ["'a1'"]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["minimax_decision('A', game52)"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"data": {"text/plain": ["'a1'"]}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": ["alphabeta_search('A', game52)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Demostrando la funci\u00f3n play_game en game52:"]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["B1\n"]}, {"data": {"text/plain": ["3"]}, "execution_count": 32, "metadata": {}, "output_type": "execute_result"}], "source": ["game52.play_game(alphabeta_player, alphabeta_player)"]}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["B2\n"]}, {"data": {"text/plain": ["12"]}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": ["game52.play_game(alphabeta_player, random_player)"]}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["current state:\n", "A\n", "available moves: ['a1', 'a2', 'a3']\n", "\n", "Your move? a1\n", "B1\n"]}, {"data": {"text/plain": ["3"]}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": ["game52.play_game(query_player, alphabeta_player)"]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["current state:\n", "B\n", "available moves: ['b1', 'b2', 'b3']\n", "\n", "Your move? b1\n", "B1\n"]}, {"data": {"text/plain": ["3"]}, "execution_count": 35, "metadata": {}, "output_type": "execute_result"}], "source": ["game52.play_game(alphabeta_player, query_player)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tenga en cuenta que si es el primer jugador, Alphabeta_player juega como MIN, y si es el segundo jugador, Alphabeta_player juega como MAX. Esto sucede porque as\u00ed es como se define el juego en la clase Fig52Game. Echar un vistazo al c\u00f3digo de esta clase deber\u00eda aclararlo."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## tres en raya\n", "\n", "Ahora juguemos al \"TicTacToe\". Primero inicializamos el juego creando una instancia de la subclase TicTacToe heredada de la clase Juego:"]}, {"cell_type": "code", "execution_count": 36, "metadata": {"collapsed": true}, "outputs": [], "source": ["ttt = TicTacToe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Podemos imprimir un estado usando el m\u00e9todo de visualizaci\u00f3n:"]}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": [". . . \n", ". . . \n", ". . . \n"]}], "source": ["ttt.display(ttt.initial)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Hmm, ese es el estado inicial del juego; sin X ni O.\n", "\n", "Creemos un nuevo estado de juego nosotros mismos para experimentar:"]}, {"cell_type": "code", "execution_count": 38, "metadata": {"collapsed": true}, "outputs": [], "source": ["my_state = GameState(\n", "    to_move = 'X',\n", "    utility = '0',\n", "    board = {(1,1): 'X', (1,2): 'O', (1,3): 'X',\n", "             (2,1): 'O',             (2,3): 'O',\n", "             (3,1): 'X',\n", "            },\n", "    moves = [(2,2), (3,2), (3,3)]\n", "    )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Entonces, \u00bfc\u00f3mo es el estado del juego?"]}, {"cell_type": "code", "execution_count": 39, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X O X \n", "O . O \n", "X . . \n"]}], "source": ["ttt.display(my_state)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["El `random_player` se comportar\u00e1 como se supone que debe hacerlo, es decir, *pseudoaleatorio*:"]}, {"cell_type": "code", "execution_count": 40, "metadata": {}, "outputs": [{"data": {"text/plain": ["(2, 2)"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["random_player(ttt, my_state)"]}, {"cell_type": "code", "execution_count": 41, "metadata": {}, "outputs": [{"data": {"text/plain": ["(2, 2)"]}, "execution_count": 41, "metadata": {}, "output_type": "execute_result"}], "source": ["random_player(ttt, my_state)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pero `alphabeta_player` siempre dar\u00e1 el mejor movimiento, como se esperaba:"]}, {"cell_type": "code", "execution_count": 42, "metadata": {}, "outputs": [{"data": {"text/plain": ["(2, 2)"]}, "execution_count": 42, "metadata": {}, "output_type": "execute_result"}], "source": ["alphabeta_player(ttt, my_state)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora hagamos que dos jugadores jueguen uno contra el otro. Usamos la funci\u00f3n `play_game` para esto. La funci\u00f3n `play_game` hace que los jugadores jueguen el partido entre s\u00ed y devuelve la utilidad para el primer jugador, del estado terminal alcanzado cuando finaliza el juego. Por lo tanto, para nuestro juego \"TicTacToe\", si obtenemos el resultado +1, el primer jugador gana, -1 si gana el segundo jugador y 0 si el partido termina en empate."]}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["O O . \n", "X O X \n", "X X O \n"]}, {"data": {"text/plain": ["-1"]}, "execution_count": 43, "metadata": {}, "output_type": "execute_result"}], "source": ["ttt.play_game(random_player, alphabeta_player)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["La salida es (normalmente) -1, porque `random_player` pierde frente a `alphabeta_player`. A veces, sin embargo, `random_player` logra dibujar con `alphabeta_player`.\n", "\n", "Dado que un `alphabeta_player` juega perfectamente, una partida entre dos `alphabeta_player`s siempre deber\u00eda terminar en empate. A ver si pasa esto:"]}, {"cell_type": "code", "execution_count": 44, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n", "X X O \n", "O O X \n", "X O X \n", "0\n"]}], "source": ["for _ in range(10):\n", "    print(ttt.play_game(alphabeta_player, alphabeta_player))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Un `random_player` nunca deber\u00eda ganar contra un `alphabeta_player`. Probemos eso."]}, {"cell_type": "code", "execution_count": 45, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["X O O \n", "X O . \n", "O X X \n", "-1\n", "O X . \n", "O X X \n", "O . . \n", "-1\n", "X X O \n", "O O X \n", "O X . \n", "-1\n", "O O O \n", ". X X \n", "X . . \n", "-1\n", "O O O \n", ". . X \n", "X . X \n", "-1\n", "O X O \n", "X O X \n", "X . O \n", "-1\n", "O X X \n", "O X X \n", "O O . \n", "-1\n", "O O X \n", "X O X \n", "X O . \n", "-1\n", "O O X \n", "X O . \n", "X O X \n", "-1\n", "O O X \n", "X X O \n", "O X X \n", "0\n"]}], "source": ["for _ in range(10):\n", "    print(ttt.play_game(random_player, alphabeta_player))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Canvas_TicTacToe(Lienzo)\n", "\n", "Esta subclase se utiliza para jugar al juego TicTacToe de forma interactiva en cuadernos Jupyter. La clase TicTacToe se llama al inicializar esta subclase.\n", "\n", "Hagamos una coincidencia entre `random_player` y `alphabeta_player`. Haga clic en el tablero para llamar a los jugadores a hacer un movimiento."]}, {"cell_type": "code", "execution_count": 46, "metadata": {"collapsed": true}, "outputs": [], "source": ["from notebook import Canvas_TicTacToe"]}, {"cell_type": "code", "execution_count": 47, "metadata": {}, "outputs": [{"data": {"text/html": ["\n", "<script type=\"text/javascript\" src=\"./js/canvas.js\"></script>\n", "<div>\n", "<canvas id=\"bot_play\" width=\"300\" height=\"350\" style=\"background:rgba(158, 167, 184, 0.2);\" onclick='click_callback(this, event, \"bot_play\")'></canvas>\n", "</div>\n", "\n", "<script> var bot_play_canvas_object = new Canvas(\"bot_play\");</script>\n"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["<script>\n", "bot_play_canvas_object.strokeWidth(5);\n", "bot_play_canvas_object.font(\"20px Arial\");\n", "bot_play_canvas_object.clear();\n", "bot_play_canvas_object.stroke(0, 0, 0);\n", "bot_play_canvas_object.line(15, 100, 285, 100);\n", "bot_play_canvas_object.line(15, 200, 285, 200);\n", "bot_play_canvas_object.line(100, 15, 100, 285);\n", "bot_play_canvas_object.line(200, 15, 200, 285);\n", "bot_play_canvas_object.fill_text(\"Player X's move(random)\", 15, 318);\n", "</script>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["bot_play = Canvas_TicTacToe('bot_play', 'random', 'alphabeta')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora, juguemos nosotros mismos contra un `jugador_aleatorio`:"]}, {"cell_type": "code", "execution_count": 48, "metadata": {}, "outputs": [{"data": {"text/html": ["\n", "<script type=\"text/javascript\" src=\"./js/canvas.js\"></script>\n", "<div>\n", "<canvas id=\"rand_play\" width=\"300\" height=\"350\" style=\"background:rgba(158, 167, 184, 0.2);\" onclick='click_callback(this, event, \"rand_play\")'></canvas>\n", "</div>\n", "\n", "<script> var rand_play_canvas_object = new Canvas(\"rand_play\");</script>\n"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["<script>\n", "rand_play_canvas_object.strokeWidth(5);\n", "rand_play_canvas_object.font(\"20px Arial\");\n", "rand_play_canvas_object.clear();\n", "rand_play_canvas_object.stroke(0, 0, 0);\n", "rand_play_canvas_object.line(15, 100, 285, 100);\n", "rand_play_canvas_object.line(15, 200, 285, 200);\n", "rand_play_canvas_object.line(100, 15, 100, 285);\n", "rand_play_canvas_object.line(200, 15, 200, 285);\n", "rand_play_canvas_object.fill_text(\"Player X's move(human)\", 15, 318);\n", "</script>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["rand_play = Canvas_TicTacToe('rand_play', 'human', 'random')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u00a1Hurra! Nosotros (normalmente) ganamos. Pero no podemos ganarle a un `alphabeta_player`, por mucho que lo intentemos."]}, {"cell_type": "code", "execution_count": 49, "metadata": {}, "outputs": [{"data": {"text/html": ["\n", "<script type=\"text/javascript\" src=\"./js/canvas.js\"></script>\n", "<div>\n", "<canvas id=\"ab_play\" width=\"300\" height=\"350\" style=\"background:rgba(158, 167, 184, 0.2);\" onclick='click_callback(this, event, \"ab_play\")'></canvas>\n", "</div>\n", "\n", "<script> var ab_play_canvas_object = new Canvas(\"ab_play\");</script>\n"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}, {"data": {"text/html": ["<script>\n", "ab_play_canvas_object.strokeWidth(5);\n", "ab_play_canvas_object.font(\"20px Arial\");\n", "ab_play_canvas_object.clear();\n", "ab_play_canvas_object.stroke(0, 0, 0);\n", "ab_play_canvas_object.line(15, 100, 285, 100);\n", "ab_play_canvas_object.line(15, 200, 285, 200);\n", "ab_play_canvas_object.line(100, 15, 100, 285);\n", "ab_play_canvas_object.line(200, 15, 200, 285);\n", "ab_play_canvas_object.fill_text(\"Player X's move(human)\", 15, 318);\n", "</script>"], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["ab_play = Canvas_TicTacToe('ab_play', 'human', 'alphabeta')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.2-final"}}, "nbformat": 4, "nbformat_minor": 1}